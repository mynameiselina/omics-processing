#!/usr/bin/env python3
"""
get the gaf file from TCGA for the gene positions
sort GAF by pos (chr and start-end) and save as csv
create a column with the correct position order
create ans save dictionary of gene names and their order
create ans save dictionary of gene names and their chr
"""
import os
import sys
import plac
import logging
from omics_processing.io import (
    load_gene_order_dict, load_clinical
)
from omics_processing.process_data import (
    load_data, split_data, clean_samples, clean_genes,
    transform_data, sort_data, save_output
)

script_path = os.path.dirname(__file__)


@plac.annotations(
    filepath=plac.Annotation(
        'File path where the gaf will be stored.',
        type=str
    ),
    outdir=plac.Annotation(
        'Folder where the output will be saved.',
        type=str
    ),
    DEBUG=plac.Annotation(
        'Set True if you want to DEBUG the code.',
        'option', 'd', bool
    )
)
def main(
    filepath=os.path.join(script_path, "..", "data", "input",
                          "gistic-cn-processed.tsv"),
    outdir=os.path.join(script_path, "..", "data", "processed"),
    data_type='cnv',
    sample_type=None,
    split_train_size=100,
    split_random_state=0,
    to_arcsinh=False,
    to_stand=True,
    to_sort_columns=True,
    gene_dict_fpath=os.path.join(script_path, "..", "data",
                                 "processed", "gaf.json"),
    to_sort_rows=True,
    sort_patients_by="grade_group",
    stratify_patients_by="grade_group",
    clinical_fpath=os.path.join(script_path, "..", "data",
                                "processed", "clinical.txt"),
    to_remove_duplicate_columns=True,
    output_directory=os.path.join(script_path, "..", "data", "processed"),
    output_filename=None,
    DEBUG=True
):
    if DEBUG:
        logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)

    sort_patients_by = sort_patients_by.rsplit(',')
    kwargs = {}
    kwargs['data_type'] = data_type
    kwargs['split_train_size'] = split_train_size
    kwargs['split_random_state'] = split_random_state
    kwargs['to_arcsinh'] = to_arcsinh
    kwargs['to_stand'] = to_stand
    kwargs['to_sort_columns'] = to_sort_columns
    kwargs['gene_dict'] = load_gene_order_dict(gene_dict_fpath)
    kwargs['to_sort_rows'] = to_sort_rows
    kwargs['sort_patients_by'] = sort_patients_by
    kwargs['clinical'] = load_clinical(clinical_fpath)
    kwargs['to_remove_duplicate_columns'] = to_remove_duplicate_columns

    if output_filename is None:
        output_filename = ''

    # load_data, split_data, clean_data, transform_data, sort_data
    data = load_data(filepath, **kwargs)
    output_filename = output_filename+kwargs['data_type']

    data = clean_samples(data, **kwargs)

    if split_train_size is not None:
        kwargs['stratify_by'] = \
            kwargs['clinical'].loc[data.index, stratify_patients_by]
        data_list = split_data(data, **kwargs)
        if kwargs['split_train_size'] < 1:
            splitname = '_split_perc' + \
                        str(int(kwargs['split_train_size']*100)) + \
                        '_seed'+str(kwargs['split_random_state'])
        else:
            splitname = '_split_size' + \
                        str(kwargs['split_train_size']) + \
                        '_seed'+str(kwargs['split_random_state'])
        output_filename = output_filename+'_'+splitname
        fname_list = [output_filename+'_part1', output_filename+'_part2']
    else:
        data_list = [data]
        fname_list = [output_filename]

    for _data, _fname in zip(data_list, fname_list):
        kwargs['sample_type'] = sample_type
        _data = clean_genes(_data)
        # in case multiple sample types exist,
        # the 'sample_type' will change inside clean_data()
        if kwargs['sample_type'] is not None:
            output_filename = output_filename+'_'+kwargs['sample_type']

        _data, transformation_settings = transform_data(_data, **kwargs)
        kwargs['transformation_settings'] = transformation_settings

        if to_sort_columns or to_sort_rows:
            _data = sort_data(_data, **kwargs)

        kwargs['output_filename'] = _fname
        save_output(_data, **kwargs)

        # if to_remove_duplicate_columns:
        #     _data = remove_andSave_duplicates(_data, **kwargs)


if __name__ == '__main__':
    plac.call(main)
